---
title: "Informe - Trabajo Práctico Regresión Logística - AyME"
author: ""
format: html
editor: visual
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(corrplot)
library(olsrr)
library(wooldridge)
library(lmtest)
library(RcmdrMisc)
library(car)
library(FactoMineR)
library(MASS)
library(tidyverse)
library(magrittr)
library(caret)
library(pROC)
library(ROCR)
library(glmulti)
library(DescTools)
```

# Cáncer de mama

## Resumen

Se ha desarrollado un sistema de diagnóstico de tumores de mama mediante técnicas interactivas de procesamiento de imágenes y un clasificador basado en programación lineal. El sistema analiza el tamaño, la forma y la textura del núcleo para calcular diez características para cada núcleo. Al probar diferentes combinaciones de características, el estudio logró una precisión del 97% al distinguir entre muestras benignas y malignas. Unas 569 imágenes se han de procesado de esta manera obteniendo las 10 variables para cada una de ellas. El objetivo de este trabajo es desarrollar un modelo de regresión logística que permita predecir si un tumor es benigno o maligno en base a las variables obtenidas.

## Introducción

La siguiente base de datos contiene información sobre 569 tumores de mama, de los cuales 357 son benignos y 212 son malignos. Para cada uno de ellos se registraron 32 variables, de las cuales 30 son numéricas y 2 son categóricas. Las variables numéricas son medidas obtenidas a partir de imágenes digitalizadas de los tumores, mientras que las variables categóricas son el diagnóstico (benigno o maligno) y el identificador del paciente. De las 30 variables numéricas, 10 son medidas obtenidas a partir de la media de las imágenes, 10 son medidas obtenidas a partir del error estándar de las imágenes y 10 son medidas obtenidas a partir del peor valor de las imágenes. Para este trabajo se utilizan las variables obtenidas a partir de la media de las imágenes para desarrollar un modelo de regresión logística que permita explicar la variable categórica diagnóstico.

## Carga de datos

Obtenemos la base de datos de la siguiente dirección: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic. La misma se encuentra comprimida y dentro en formato csv. La cargamos en R y la guardamos en un objeto y mantenemos las variables que nos interesan con nombres más cortos y descriptivos en español.

Aparte, analizamos las variables predictoras que contienen las medias porque resultan más sencillas para comunicar los resultados, y porque expresan con mayor claridad la situación de cada caso. En contraposición, las variables que expresan los errores estándar o los valores límite, resultan más complejas de comunicar o analizar.

```{r}

download.file("https://archive.ics.uci.edu/static/public/17/breast+cancer+wisconsin+diagnostic.zip", "data/breast+cancer+wisconsin+diagnostic.zip")

unzip("data/breast+cancer+wisconsin+diagnostic.zip", exdir = "data")

cmama <- read.csv ("data/wdbc.data", header = FALSE)

cmama2 <- cmama [, c(2:12)] #Recorte de datos
colnames (cmama2) <-
  c(
    "diagnostico",
    "radio_medio",
    "textura_media",
    "perimetro_medio",
    "area_media",
    "uniformidad_media",
    "compactabilidad_media",
    "concavidad_media",
    "puntos_concavos_medios",
    "simetria_media", 
    "dimension_fractal_media")

cmama2$diagnostico <- ifelse (cmama2$diagnostico == "B", 0, 1)
glimpse(cmama2)
```

Además, definimos la problemática: el criterio de diagnóstico ¿es explicada por las variables vinculadas al tamaño, la textura y la forma del tumor? ¿De que manera?

## Análisis exploratorio

La variable dependiente es la variable dicotómica *diagnóstico*, que toma el valor 0 si el tumor es benigno y 1 si el tumor es maligno.

```{r warning=FALSE}
cmama2 %>%
  ggplot(aes(x = factor(diagnostico), fill = factor(diagnostico))) +
  geom_bar() +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_text(stat = "count", aes(label = ..count..), vjust = 2)
```

Las 10 variables cuantitativas continuas independientes refieren a medidas de los tumores:

a)  radio (media de las distancias desde el centro hasta puntos en el perímetro)
b)  textura (desviación estándar de los valores de escala de grises)
c)  perímetro
d)  área
e)  suavidad o uniformidad (variación local en longitudes de radio)
f)  compacidad (perímetro\^2 / área - 1.0)
g)  concavidad (severidad de porciones cóncavas del contorno)
h)  puntos cóncavos (número de porciones cóncavas del contorno)
i)  simetría
j)  dimensión fractal ("aproximación de la línea costera" - 1)

```{r}
cmama2 %>%
  gather(key = "variable", value = "value", -diagnostico) %>%
  ggplot(aes(x = value, fill = factor(diagnostico))) +
  geom_density(alpha = 0.5) +
  facet_wrap(~variable, scales = "free") +
  theme_minimal() +
  theme(legend.position = "none")
```

También, descartamos la posibilidad de valores faltantes o duplicados

```{r}
anyNA (cmama2) #No hay valores faltantes
anyDuplicated (cmama2) #No hay elementos duplicados
```

## Correlación entre variables

Analizamos la correlación entre las variables independientes.

```{r}
cmama2 %>%
  select(-diagnostico) %>%
  cor() %>%
  corrplot(method = "circle", type = "upper", tl.col = "black", tl.srt = 45)
```

Observamos, por ejemplo, que las variables radio, perímetro y área están altamente correlacionadas entre sí. Decidimos listar las correlaciones más altas para ver si hay alguna que sea mayor a 0.7.

```{r}
cmama2 %>%
  select(-diagnostico) %>%
  cor() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  gather(key = "variable2", value = "correlacion", -variable) %>%
  transmute(variables=paste(pmin(variable, variable2), "-", pmax(variable, variable2)), correlacion) %>%
  distinct() %>%
  filter(correlacion > 0.7, correlacion < 1) %>%
  arrange(desc(correlacion))
```

También, construimos un modelo preliminar y revisamos la variabilidad de los datos en aquellas variables que están muy correlacionadas

```{r warning=FALSE}
#Diagnóstico de los datos

modelo <-
  glm (
    diagnostico ~ radio_medio + textura_media + perimetro_medio + area_media + uniformidad_media + compactabilidad_media + concavidad_media + puntos_concavos_medios + simetria_media + dimension_fractal_media,
    family = binomial(link = "logit"),
    data = cmama2
  )

#Diagnostico: colinealidad
vif (modelo)
```

Debido a que el modelo inicial presenta variables explicativas altamente correlacionadas, buscamos un modelo que pueda explicar de manera precisa el diagnóstico en base a las medidas de tamaño, textura y forma del tumor, pero con la eliminación de aquellas variables predictoras están altamente correlacionadas y que complican la precisión y explicación del modelo.

```{r warning=FALSE}
stepwise(modelo)
```

## Postulación del modelo

Así, se arriba a un modelo más sencillo, más preciso y que explica mejor el criterio de diagnóstico en base a las medidas del tamaño, la textura y la forma del tumor, mediante el criterio de información de Akkaike

```{r}
cmama3 <- cmama2[, c(1, 3, 5, 9)]

modelo_aic <- glm(diagnostico ~ ., family = binomial(link = "logit"), cmama3)

summary(modelo_aic)
```

## Verificación del modelo

Verificamos que el factor de inflación de la varianza (VIF) de cada variable sea menor a 5.

```{r}
vif(modelo_aic)
```

## Interpretación del modelo

Coeficientes e intervalos de confianza para cada variable predictora.

```{r}
exp(cbind(coef(modelo_aic),confint.default(modelo_aic)))
```

Por cada aumento en una unidad de la textura media del tumor, se estima que la chance de que el diagnóstico del tumor sea maligno aumenta entre $1.242$ y $1.544$.

Por cada aumento en una unidad del área media del tumor, se estima que la chance de que el diagnóstico del tumor sea maligno aumenta entre $1.005$ y $1.011$.

Por cada aumento en una unidad de la cantidad de puntos cóncavos medios del tumor, se estima que la chance de que el diagnóstico sea que el tumor sea maligno aumenta entre $8.968 \times 10^{32}$ y $1.991 \times 10^{55}$.

## Pseudo $R^2$

Se mide la reducción proporcional de la variación en el criterio de Diagnóstico al utilizar las variables de Textura, Área y Puntos Cóncavos medios. El coeficiente de determinación $R^2$ de Nagelkerke suele ser más bajo que el coeficiente de determinación de $R^2$.

```{r}
PseudoR2(modelo_aic, which = c("Nagelkerke"))
```

Por lo tanto, hay una reducción del 88% de la variación en el criterio de Diagnóstico

## Prueba de Bondad de Ajuste Hosmer-Lemeshow

Se realiza una prueba de bondad de ajuste del modelo de regresión logística.

La hipótesis nula es que el modelo está bien ajustado

Y la hipótesis alternativa es que no lo está.

El estadístico de la prueba es el Chi-Cuadrado de Pearson con nivel de significancia de 0.95 y 10 (clases) - 2 grados de libertad

```{r}
HosmerLemeshowTest(fit = fitted(modelo_aic), obs = cmama3$diagnostico)$C
```

```{r}
#Creación curva de densidad
x <- 3.4834
curve(dchisq(x, 8), from = 0, to = 40,
      main = 'Prueba de Bondad de Ajuste Hosmer-Lemeshow (gl = 8)', xlab = 'Estadístico C',
      ylab = 'Densidad de Probabilidad',
      lwd = 2)

#Crear vector de valores chi teoricos
x_teor <- seq(qchisq(0.95,8), 40)

#Crear vector de p-Valor
p_vector <- dchisq(x_teor, 8)

#Rellenado
polygon(c(x_teor, rev(x_teor)), c(p_vector, rep(0, length(p_vector))),
        col = adjustcolor('red', alpha=0.3), border = NA)

#Crear vector de valor observado
x_obs <- seq(x, 40)

#Crear vector de p-Valor
p_vector <- dchisq(x_obs, 8)

#Rellenado
polygon(c(x_obs, rev(x_obs)), c(p_vector, rep(0, length(p_vector))),
        col = adjustcolor('green', alpha=0.3), border = NA)
```


La prueba de hipótesis no rechaza la hipótesis nula.

Por lo tanto, el modelo de regresión logística está bien ajustado.

## Predicción del modelo

Predicción de la probabilidad de que el tumor sea maligno.

```{r}
referencia <- cmama3$diagnostico
prediccion <- predict(modelo_aic, type="response")
```

Curva ROC y área bajo la curva ROC.

```{r}
curva <- roc(referencia, prediccion)
plot(1-curva$specificities, curva$sensitivities, type="l",xlab="1-Especificidad",ylab="Sensibilidad",lwd=2,col="blue",xaxs="i",yaxs="i")
segments(0,0,1,1,lwd=2,col="red")

# Area bajo la curva ROC
(areaRoc<-auc(referencia, prediccion)); ci(areaRoc)
```

Corte óptimo de la curva ROC

```{r}
(opt <- coords(curva, "best", ret=c("threshold", "specificity", "sensitivity", "accuracy",
                                  "tn", "tp", "fn", "fp")))
```

Tabla de clasificación

```{r}
# Según corte óptimo de corte por Youden
prediccion_clases <- ifelse(prediccion > opt$threshold, 1, 0)
confusionMatrix(data = factor(prediccion_clases), reference = factor(cmama3$diagnostico), positive = "1")
```

## Conclusión

