##############################
####  Heterocedasticidad  ####
##############################

################
#### Seteo  ####
################

#Ruta de la pc
{#setwd("C:\\Users\\carlo\\Dropbox\\Archivos de Apuntes\\Regresion Lineal\\Heterocedasticidad\\Bases y Sintaxis")

#Limpiamos, guardamos los parámetros gráficos básicos y notacion científica
rm(list=ls())
oldpar<-par(no.readonly = TRUE)
options(scipen=99, digits=6)

#####################################
#### Instalación y carga         ####
####  de la librerías necesarias ####
#####################################

library("Hmisc")
library("lmtest")
library("MASS")       #Para transformación de Box-Cox
library("sandwich")   #Heterocedasticidad Consistente
library("wooldridge") #Ejercicios de Wooldridge
library("regresion")  #Para grafico de pruebas
library("olsrr")      #Para salidas de regresion
library("corrplot")   #Para grafico de correlaciones
library("stargazer")  #Para tablas comparativas
library("car")        #âra QQ Plot
library("strucchange")
}

###########################
#### Funciones a usar  ####
###########################

#Esta función rearma la tabla ANOVA
anva<-function(x){
  x<-anova(x)
  a<-sum(x[1:(nrow(x)-1),1]);a
  b<-x[nrow(x),1];b
  c<-sum(x[,1]);c
  d<-sum(x[1:(nrow(x)-1),2]);d
  e<-x[nrow(x),2];e
  f<-sum(x[,2]);f
  g<-d/a;g
  h<-e/b;h
  i<-g/h;i
  j<-pf(i,a,b,lower.tail = FALSE);j
  
  k<-data.frame(Fuente=c("Regresion","Residuos","Total"),Gl=c(a,b,c),"Suma Cuadrados"=c(d,e,f),`Cuadrados Medios`=c(round(g,4),round(h,4),NA),
                `Prueba F`=c(round(i,4),NA,NA),`P Value`=c(round(j,6),NA,NA),check.names = F)
  k[is.na(k)] <- ""
  return(k)}

##############################
#### Levantamos la base   ####
#### y armamos los datos  ####
##############################

#Ejemplo 8.4 Wooldridge Pag 278
data("hprice1")
hprice1
datos <- hprice1[,c("price","lotsize","sqrft","bdrms")]

attach(datos)

#Y  = precio de la propiedad en miles
#X1 = tamaño del terreno en pies cuadrados
#X2 = tamaño de la casa
#X3 = Cantidad de dormitorios

#################################
####  Análisis Exploratorio  ####
####    de la variables      ####
#################################

#Gráfico de Dispersión Matricial
pairs(datos,pch=19,col="red")

#Gráfico de la matriz de correlaciones
{col <- colorRampPalette(c("red","yellow","deepskyblue"))
  corrplot(cor(datos),type="upper",tl.pos = "d",main = "Matriz de Correlaciones",mar=c(3,3,3,3),col=col(200))
  corrplot(cor(datos),method = "number",type="lower",add=T,diag = F,tl.pos = "n",cl.pos = "n",number.digits = 4,col=col(200))
}

#Matriz de correlaciones
cor(datos)

#Hacemos los boxplots separados por las diferentes escalas de las variables
{
par(mfrow=c(2,2),mar=c(2,2,2,2))
boxplot(price,horizontal = T,col="red",main="Precio de la propiedad",pch=19)
boxplot(lotsize,horizontal = T,col="green4",main="Tamaño del terreno",pch=19)
boxplot(sqrft,horizontal = T,col="deepskyblue",main="Tamaño de la casa",pch=19)
boxplot(bdrms,horizontal = T,col="orange",main="Dormitorios",pch=19)
}

#################################
####  Análisis de Regresión  ####
####     Múltiple            ####
#################################

#Hacemos la regresion
reg <- lm(price ~. ,data = datos)

#1 - ¿Que es la homocedasticidad? ?Que la causa? ?Cu?les son las consecuencias?
#2 - ¿Que signos de evidencia de heterocedasticidad pueden verse en las tablas? Ninguno
#3 - En caso de encontrar un coeficiente no significativo ¿Se elimina del modelo? No lo podemos asegurar

#Analizamos las tablas iniciales
ols_regress(reg)

#############################
#### Pruebas Informales  ####
#############################

#Hacemos un gráfico de dispersión para los residuos contra los ajustados
{
par(oldpar)
plot(reg$fitted.values,reg$residuals,xlab = "Valores Predichos",ylab = "Residuos observados",pch=19, col="blue",main = "Grafico de Residuales sobre Predichos")
abline(h=0,col="red",lwd=2)
}

#Hacemos el gráfico con los residuos estandart
{plot(reg$fitted.values,rstandard(reg),xlab = "Valores Predichos",pch=19,col="red",type = "p",
     ylab = "Residuos Standart",ylim = c(-3,3),main="Residuos Standart sobre Predichos")
abline(h=c(-2,2),lwd=2,col="green4")
}

##########################
#### Prueba Formales  ####
##########################

###########################
#### Prueba de Harvey  ####
###########################

#Trabaja en base a los residuos recursivos que son cada residuos generado por la ultima observacion al incorporar una observacion.
#La hipotesis plantea un error de especificacion del modelo al probar si los residuos recursivos tienen forma concava o lineal

harvtest(reg)

s <- strucchange::recresid(reg)
plot(cumsum(s),type = "l")

###############################
####Prueba de Breusch-Pagan####
###############################

#Diferencia con el test estudentizado
#https://stats.stackexchange.com/questions/193061/what-is-the-difference-between-these-two-breusch-pagan-tests

#Gujarati informa este
bp<-bptest(reg,studentize = F)

#Wooldridge informa este
bp1<-bptest(reg,studentize = T)

#Vemos los resultados
bp
bp1

#Probemos manualmente el no estudentizado
#Elevamos los residuos al cuadrado y !!OJO ACA!!LO DIVIDIMOS POR LA SUMA CUADRADO DE RESIDUOS SOBRE N
#ESTO ES PORQUE USA EL ESTIMADOR DE MV Y NO EL DE MCO
{pi<-reg$residuals^2/(anva(reg)[2,3]/nrow(datos))
  
#Regresamos pi contra las independientes del modelo original
reg.pi<-lm(pi~ lotsize + sqrft + bdrms ,data=datos)
  
#Guardamos la SC Regresión
SCR <- anva(reg.pi)[1,3]
  
#Los grados de libertad son los betas de la regresión sin B0
gl<-length(reg.pi$coefficients)-1
  
#Generamos el estadistico lambda = Suma de  Cuadrados Explicados/2
lambda<-SCR/2
cat(paste("El valor del estadistico es BP Studentizado es ",round(lambda,digits = 4)))
}

#Construimos el estudentizado
bp_e <- summary(reg.pi)$r.squared * nrow(datos)
cat(paste("El valor del estadistico es BP Studentizado es ",round(bp_n,digits = 4)))

#Que tiene distribución chi con betas sin b0 grados de libertad (1)
{(pv.lambda<-pchisq(bp_e,3,lower.tail = FALSE))
  cat(paste("El P-Value es",round(pv.lambda,digits = 4)))}

#Vemos el grafico
{alfa<-0.95
  values<-seq(0,lambda*1.2,.1)
  probs<-dchisq(values, gl)
  plot(values, probs, axes = F, type = "n", xlab = "Valores de X",
       ylab = "Probabilidad",cex.axis=.8,
       main = "Prueba Chi Cuadrado de Breusch-Pagan")
  axis(1, pos = 0,cex.axis=.8)
  axis(2, pos = 0,cex.axis=.8)
  lines(values, probs, col = 2,lwd=2)
  chicritico<-qchisq(alfa,gl)
  u = seq(chicritico,chicritico*2,length=601)
  lines(u,dchisq(u,gl),type="h",col="red")
  pvchi<-pchisq(lambda,gl,lower.tail = FALSE)
  
  lines(chicritico,dchisq(chicritico,gl) ,type="h",col="red",lwd=3)
  text(chicritico,dchisq(chicritico,gl)*2,bquote(paste(chi[c]^2," = ",.(round(chicritico,3)))),cex=1.1,font = 2,col="blue")
  
  lines(lambda,dchisq(lambda,gl) ,type="h",col="green4",lwd=3)
  text(lambda,dchisq(lambda,gl)*2,bquote(paste(lambda[obs]," = ",.(round(lambda,3)))),cex=1.1,font = 3,col="blue")
  
  text(chicritico,dchisq(chicritico,gl)*5,paste("PV =",round(pvchi,3)),col="blue",font=2)
}

##################################
### Prueba de Goldfeld-Quant  ####
##################################

#Probamos cada variable comenzando por "lotsize"
gqgrafico(reg,8,orden = datos$lotsize) #suponemo qe el tamaño del lote hace quilombo

#Los argumentos de la funcion son:
#Objeto a analizar = en nuestro caso "reg"
#fraction = cantidad de observaciones centrales a eliminar
#order.by = variable que se sospecha genera la hetero y se usa para ordenar los datos
centro=8
gqtest(reg,fraction = centro,order.by = datos$lotsize) #por poco no generqa problemas

#Pasamos a sqrft
gqgrafico(reg,8,orden = datos$sqrft)
gqtest(reg,fraction = centro,order.by = datos$sqrft) #no genera problmas

#Por ultimo "bdrms"
gqgrafico(reg,8,orden = datos$bdrms)
gqtest(reg,fraction = centro,order.by = datos$bdrms) #Si genera problemas


#Para hacerlo de forma manual

#Definimos la cantidad de datos centrales que no vamos a tomar y el total de los datos
{
centro<-8
n<-nrow(datos)
  
#Ordenamos los datos por la sospechosa en forma ascendente (descendente deberiamos poner un menos en empresa despues de order)
data<-datos[ order(datos[,4]), ]
  
#En funcion a tener definido la cantidad total de datos y los centrales a eliminar, tomamos el primer subset de 13 datos
reg1.datos<-lm( price ~ lotsize + sqrft + bdrms,subset(data[1:((n-centro)/2),]))
reg2.datos<-lm( price ~ lotsize + sqrft + bdrms,subset(data[((n+centro+2)/2):n,]))

#Guardamos de ANOVA las SC residuos de ambas regresiones
SCR1<-anva(reg1.datos)[2,3]
SCR2<-anva(reg2.datos)[2,3]  

#Como los dos grupos tienen el mismo tamaño, los gl son iguales
gl1 = gl2 = (n-centro-2*ncol(data)) / 2 

f<-(SCR2/gl2)/(SCR1/gl1)
pv.f<-pf(f,gl1,gl2,lower.tail = FALSE)
cat(paste("El valor del estadistico es",round(f,digits = 4),"con GL de", gl1 , 
          "y un PV de ",round(pv.f,digits = 4)))

}

#Hacemos el grafico de la F
{alfa<-0.95
  values<-seq(0,f*1.2,.02)
  probs<-df(values, gl2, gl1)
  plot(values, probs, axes = F, type = "n", xlab = "Valores de X",
       ylab = "Probabilidad",cex.axis=.8,
       main = "Prueba F de Goldfield-Quant")
  axis(1, pos = 0,cex.axis=.8)
  axis(2, pos = 0,cex.axis=.8)
  lines(values, probs, col = 2,lwd=2)
  
  fcritico<-qf(alfa,gl2,gl1)
  lines(fcritico,df(fcritico,gl2,gl1) ,type="h",col="red",lwd=3)
  text(fcritico,df(fcritico,gl2,gl1)*2,bquote(paste(F[n]," = ",.(round(fcritico,3)))),cex=1.1,font = 2,col="blue")
  u = seq(fcritico,fcritico*2,length=601)
  lines(u,df(u,gl2,gl1),type="h",col="red")
  
  lines(f,df(f,gl2,gl1) ,type="h",col="green4",lwd=3)
  text(f,df(f,gl2,gl1)*2,bquote(paste(F[obs]," = ",.(round(f,3)))),cex=1.1,font = 3,col="blue")
  
  pvf<-pf(f,gl2,gl1,lower.tail = FALSE)
  text(fcritico,df(fcritico,gl2,gl1)*5,paste("PV =",round(pvf,3)),col="blue",font=2)
}

#######################
####Prueba de White####
#######################

#Funcion extraida de:
#https://github.com/cran/bstats/blob/master/R/whitetest.R
white.test(reg)

#Lo aramos manualmente
#Tomamos el R2 de la regresion auxiliar y la cantidad de datos
{
delta<-white.test(reg)[[2]][["r.squared"]] * n
gl <- white.test(reg)[[1]][["parameter"]]
pv.delta<-pchisq(delta,gl,lower.tail = FALSE)
cat(paste("El valor del estadistico es",round(delta,digits = 4),"con GL de", gl , 
          "y un PV de ",round(pv.delta,digits = 8)))
}

#Vemos el gráfico
{alfa<-0.95
  values<-seq(0,delta*1.2,.1)
  probs<-dchisq(values, gl)
  plot(values, probs, axes = F, type = "n", xlab = "Valores de X",
       ylab = "Probabilidad",cex.axis=.8,
       main = "Prueba Chi Cuadrado de White")
  axis(1, pos = 0,cex.axis=.8)
  axis(2, pos = 0,cex.axis=.8)
  lines(values, probs, col = 2,lwd=2)
  u = seq(chicritico,chicritico*2,length=601)
  lines(u,dchisq(u,gl),type="h",col="red")
  chicritico<-qchisq(alfa,gl)
  pvchi<-pchisq(delta,gl,lower.tail = FALSE)
  
  lines(chicritico,dchisq(chicritico,gl) ,type="h",col="red",lwd=3)
  text(chicritico,dchisq(chicritico,gl)*2,bquote(paste(chi[c]^2," = ",.(round(chicritico,3)))),cex=1.1,font = 2,col="blue")
  
  lines(delta,dchisq(delta,gl) ,type="h",col="green4",lwd=3)
  text(delta,dchisq(delta,gl)*2,bquote(paste(delta[obs]," = ",.(round(delta,3)))),cex=1.1,font = 3,col="blue")
  
  text(chicritico,dchisq(chicritico,gl)*5,paste("PV =",round(pvchi,6)),col="blue",font=2)
}

#########################
#### Prueba de White ####
####   Reducida      ####
#########################
#Woolridge Pag 278-280

#Por tener 3 variables independientes, perdemos 9 grados de libertad, para esto se usa esta prueba.
#Para hacer la prueba de White, usamos los residuos, los estimados y los cuadrados de los estimados
{
reg2<-lm(reg$residuals^2~reg$fitted.values+I(reg$fitted.values^2))

#Tomamos el valor del R2 de esta regresion y lo multiplicamos por n
est<-summary(reg2)$r.squared*nrow(datos)

#Calculamos el valor-p para una distribucion Chi con 2 grados de libertad
pv.w <- pchisq(est,2,lower.tail = F)
cat(paste("El valor del estadistico es",round(est,digits = 4),"con GL de", 2 , 
          "y un PV de ",round(pv.w,digits = 4)))
}

######################
####Prueba de Park####
######################

#Dado que las pruebas arrojaron mas sosepchas sobre "lotsize", usamos esta variable
#Generamos los datos nuevos, necesitamos el logaritmo de los residuos al cuadrado y el logaritmo de la dependiente
{c<-data.frame("Ln Res C"=log(reg$residuals^2),lotsize=log(lotsize),check.names = F)

plot(c$lotsize,c$Log.Resi,pch=19,col="red")

#Hacemos la regresion y pedimos la tabla de coeficientes parciales.
d<-lm(`Ln Res C`~lotsize,data=c)
summary(d)
}

#########################
####Prueba de Glejser####
#########################
#Vamos a probar diferentes formas funcionales haciendo primero la grafica y analizando la tabla de coeficientes.

#Regresión y gráfico sobre la variable X

{regA<-lm(abs(reg$residuals) ~ datos$lotsize)
plot(datos$lotsize,abs(reg$residuals),xlab = "VENTAS",ylab = "Residuos Absolutos",pch=19, col="blue",main="Variable X Lineal")
abline(coef = coef(regA),col="red",lwd=2)
summary(regA)
}

#Regresión y gráfico sobre la raiz de la variable X.
{regB<-lm(abs(reg$residuals)~sqrt(datos$lotsize))
  plot(sqrt(datos$lotsize),abs(reg$residuals),xlab = "Raiz de VENTAS",ylab = "Residuos Absolutos",pch=19, col="blue",main="Variable Raiz de X")
  abline(coef = coef(regB),col="red",lwd=2)
  summary(regB)
}

#Regresión y gráfico sobre la inversa de la variable X
#Creamos primero la variable i.ventas como la inversa
{i.ventas<-1/datos$lotsize
  regC<-lm(abs(reg$residuals) ~ i.ventas)
  plot(i.ventas,abs(reg$residuals),xlab = "VENTAS",ylab = "Residuos Absolutos",pch=19, col="blue",main="Variable Inversa de X ")
  abline(coef = coef(regC),col="red",lwd=2)
  summary(regC)
}

#Regresión sobre la raíz de la inversa de X
{regD<-lm(abs(reg$residuals)~sqrt(i.ventas))
  plot(sqrt(i.ventas),abs(reg$residuals),xlab = "Raiz de la Inversa de X",ylab = "Residuos Absolutos",pch=19, col="blue",main="Variable Raiz de la Inversa de X")
  abline(coef = coef(regD),col="red",lwd=2)
  summary(regD)
}

#############################
####  Minimos Cuadrados  #### 
####     Ponderados      ####
#############################

#Wooldridge Pag 284
datos<-k401ksubs

#Tomamos los datos de los solteros (familysize=1) para las regresiones
regP1<-lm(nettfa ~ inc, data =datos[datos$fsize==1,])
regP2<-lm(nettfa ~ inc + male + e401k + I((age-25)^2), data =datos[datos$fsize==1,])

#La variable de ponderacion es el ingreso en miles de dolares que es la columna 2 de la base
regP3<-lm(nettfa ~ inc, data =datos[datos$fsize==1,],weights = 1/datos[datos$fsize==1,2])
regP4<-lm(nettfa ~ inc + male + e401k + I((age-25)^2), data =datos[datos$fsize==1,],weights = 1/datos[datos$fsize==1,2])

stargazer(regP1, regP3, regP2, regP4, type="text",column.labels = c("MCO","MCP","MCO","MCP"),
          dep.var.labels = "Ingreso Neto Familiar")

##########################################################
#Analisis de "Minimos Cuadrados Ponderados.pdf" de Drapper
##########################################################

#Levantamos la base completa
{hetero<-spss.get("Regresion Multiple Heterocedasticidad.sav")

#Como son tres bases unidas, vemos que tiene problemitas, por eso la dividimos y arreglamos
#La dividimos en las tres manteniendo el mismo nombre
salud<-data.frame(Sujeto=hetero$Sujeto,Edad=hetero$Edad,Presion=hetero$Presion)

#Limpiamos "empresa" que tiene datos faltantes y "agro" tambien tiene datos faltantes dado que empresa tenia mas datos
salud<-salud[-(55:131),]
}

#Con esta base vamos a trabajar
attach(salud)

#Hacemos la regresion donde "Peso" es lo que queremos explicar
regresion<-lm(Presion~Edad)
ols_regress(regresion)

#Guardamos ANOVA
{anova.regresion<-anova(regresion)

#Trafico de dispersión de los datos con la recta
plot(Edad,Presion,xlab="Edad en Edad",ylab="Peso",pch=19,col="red")
abline(regresion,lwd=2,col="green4")
}

#Vemos que la recta de regresión genera que los valores grandes de edad estén mas dispersos

#Dibujamos los valores predichos sobre los residuos
plot(regresion$fitted.values,regresion$residuals,xlab="Valores Ajustados",ylab="Residuos",col="blue",pch=19)

#Dibujo de los predichos sobre los standart, entonces guardamos los residuos
#Ponemos una linea en dos para ver que esta pasando
{rst<-rstandard(regresion)
plot(regresion$fitted.values,rst,xlab="Valores Ajustados",ylab="Residuos Standart",col="darkgray",pch=19)
abline(h=c(2,-2))}

#Residuos standart contra la independiente
plot(Edad,rst,xlab="Edad",ylab="Residuos Standart",col="darkgreen",pch=19)

#A traves de los graficos podemos ver que a medida que aumenta la edad de la persona
#los errores aumentan, con esto decimos que x genera heterocedasticidad
#El investigador supone que cada grupo etario posee su varianza y se incrementa a medida que la edad crece
#Creamos una variable factor para cada grupo etario y añadimos a la base los residuos standart

{salud$grupo[salud$Edad<30]<-1
salud$grupo[salud$Edad>=30 & salud$Edad<40]<-2
salud$grupo[salud$Edad>=40 & salud$Edad<50]<-3
salud$grupo[salud$Edad>=50]<-4
salud<-data.frame(salud,rst)

#Vemos el resultado
(salud)}

#Hacemos el box plot de los residuos por grupo etario, si fuera homocedastico, deberia ser similares
boxplot(rst~salud$grupo,xlab="Grupo Etario",ylab="Residuos Standart",col=c("red","green4","orange","deepskyblue"))

#Hacemos el mismo grafico de los residuos standart distinguiendo cada grupo
{plot(salud[salud$grupo==1,"Edad"],salud[salud$grupo==1,"rst"],col="red",pch=19,xlab = "Edad",ylab = "Residuos Standart",xlim = c(20,60),ylim = c(-2.5,2.5))
points(salud[salud$grupo==2,"Edad"],salud[salud$grupo==2,"rst"],col="blue",pch=19)
points(salud[salud$grupo==3,"Edad"],salud[salud$grupo==3,"rst"],col="green",pch=19)
points(salud[salud$grupo==4,"Edad"],salud[salud$grupo==4,"rst"],col="orange",pch=19)
legend("topleft",legend = c("20 a 30 años","30 a 40 años","40 a 50 años","50 a 60 años"),bty="n",col=c("red","blue","green","orange"),pch=19)
}

#Corremos las regresiones para cada grupo recordando que
#El investigador supone que la cada grupo etario posee su varianza y se incrementa a medida que la edad crece
#Esta suposición hace que sea posible hacer MCP
{reg.g1<-lm(Presion~Edad,subset=(grupo==1),data=salud);summary(reg.g1);anova.g1<-anova(reg.g1)
reg.g2<-lm(Presion~Edad,subset=(grupo==2),data=salud);summary(reg.g2);anova.g2<-anova(reg.g2)
reg.g3<-lm(Presion~Edad,subset=(grupo==3),data=salud);summary(reg.g3);anova.g3<-anova(reg.g3)
reg.g4<-lm(Presion~Edad,subset=(grupo==4),data=salud);summary(reg.g4);anova.g4<-anova(reg.g4)
}

#Veamos ahora los CME de cada grupo
anova.g1
anova.g2
anova.g3
anova.g4

#Creamos los cuatro ponderadores como la inversa del promedio de cuadrados de cada regresion
{(a<-1/anova.g1[2,3])
(b<-1/anova.g2[2,3])
(c<-1/anova.g3[2,3])
(d<-1/anova.g4[2,3])
}

#Creamos una columna para ponderar
{salud$pondera[salud$grupo==1]<-a
salud$pondera[salud$grupo==2]<-b
salud$pondera[salud$grupo==3]<-c
salud$pondera[salud$grupo==4]<-d}

#Chequeamos
salud

#Hacemos la regresion ponderada por la nueva variable y pedimos ambas salidas de coeficientes
#¿QUE CAMBIA ENTRE AMBAS SALIDAS?
(reg.pondera<-lm(Presion~Edad,weights=pondera,data=salud));summary(regresion);summary(reg.pondera)

plot(regresion$fitted.values,regresion$residuals,xlab="Valores Ajustados",ylab="Residuos",col="blue",pch=19)
plot(reg.pondera$fitted.values,reg.pondera$residuals,xlab="Valores Ajustados",ylab="Residuos",col="blue",pch=19)

######################################################
####Transformacion de Box-Cox Ejercicio de Drapper####
######################################################

#Levantamos la base con los datos, la primera fila es nombre, por eso header
{drapper<-read.table("C:/Users/carlo/Dropbox/Archivos de Apuntes/Regresion Lineal/Heterocedasticidad/Bases y Sintaxis/Datos Box Cox.txt",header = TRUE);drapper

#Fijamos la base
attach(drapper)

#Cargamos la libreria
library("MASS")

#Corremos la regresión normal de los datos
regboxcox<-lm(Y~X1+X2)
}

#Corremos la transformación, al ver el resultado, los x son los lambda entre -2 y 2 y los y
#son logaritmos de las verosimilitudes
bc<-MASS::boxcox(Y~X1+X2,lambda = seq(-1, 1, len=21),plotit=T);bc

#Buscamos el maximo de L y vemos a que valor de lambda corresponde
(Lmax<-bc$x[which.max(bc$y)])

#Hacemos el QQ plot de la regresión original
qqPlot(regboxcox$residuals,pch=19,col="red")

####Transformacion de Box-Cox####
library(MASS)

# GENERAMOS DATOS ALEATORIOS
set.seed(1)
n <- 100
x <- runif(n, 1, 5)
y <- x^3 + rnorm(n)

# CORREMOS LA REGRESION LINEAL QUE LLAMAMOS "m"
m <- lm(y ~ x)

# CORREMOS LA TRANSFORMACION DE BOX COX QUE LLAMAMOS "bc"
bc <- boxcox(y ~ x)

#LE PEDIMOS QUE NOS DIGA CUAL ES EL LAMBDA QUE PRODUCE EL MENOR ERROR
(trans <- bc$x[which.max(bc$y)])

#Un grafico mas completo que permite ver la curva y otras cosas
{plot(bc$x,bc$y,type="l",lwd=2,col="blue",xlab = "Lambda",ylab = "Desvio",main="Curva de Desvios por Lambda")
segments(bc$x[which.max(bc$y)],min(bc$y),bc$x[which.max(bc$y)],max(bc$y),lwd=2,col="green4")
legend("topleft",legend =bquote(atop(paste("Desvio = ",.(max(bc$y))),paste(lambda," = ",.(bc$x[which.max(bc$y)])))),bty="n",cex = 1)
}

################################
####  Minimos Cuadrados     ####
#### Factibles - Wooldridge ####
################################

#Ejemplo 8.7 - Pag 288
#Hacemos la regresion original
reg8<-lm(cigs~log(income)+log(cigpric)+educ+age+I(age^2)+restaurn,data=smoke);summary(reg8)
plot(reg8$fitted.values,reg8$residuals,xlab="Valores Ajustados",ylab="Residuos",col="blue",pch=19)

#Usamos el ln de los residuos al cuadrado como dependiente
mcf<-lm(log(reg8$residuals^2)~log(income)+log(cigpric)+educ+age+I(age^2)+restaurn,data=smoke);summary(mcf)

#Creamos el ponderador como exp de los ajustados
h<-1/exp(mcf$fitted.values)

head(h)

reg9<-lm(cigs~log(income)+log(cigpric)+educ+age+I(age^2)+restaurn,data=smoke,weights=h);summary(reg9)
plot(reg9$fitted.values,reg9$residuals,xlab="Valores Ajustados",ylab="Residuos",col="blue",pch=19)

##########################################
####  Heterocedasticidad Consistente  ####
##########################################

#Vemos los coeficientes originales
summary(reg)

#Y los consistentes HC3, la funcion "vcovHC" es para lo consistente.
coeftest(reg,vcov =vcovHC(reg,type = "HC3"))

#Armamos la diagonal con los desvios consistentes
cov1         <- vcovHC(reg, type = "HC1")
robusto    <- sqrt(diag(cov1))

# Stargazer output (with and without RSE)
stargazer(reg, reg, type = "text",
          se = list(NULL, robusto))